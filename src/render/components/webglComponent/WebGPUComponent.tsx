import { useEffect } from "react"
// import "@webgpu/types"
import FragmentShaderCode from "./wgsl/fragmentModule.wgsl?raw"
import VertexShaderCode from "./wgsl/vertexModule.wgsl?raw"

import TriangleVertexShaderCode from "./wgsl/triangleVertex.wgsl?raw"
import TriangleFramentShaderCode from "./wgsl/triangleFrament.wgsl?raw"
import "./webgc.css"

function WebGPUComponent() {
    useEffect(() => {
        renderGPU()
    }, [])
    return (
        <div className="webgpu-body">
            <canvas id="webGPUCanvas" width="512" height="300">
                Oops ... your browser doesn't support the HTML5 canvas element
            </canvas>
        </div>
    )

    /**
     * åˆå§‹åŒ–GPUå¯¹è±¡
     * 1ã€é¦–å…ˆåœ¨æµè§ˆå™¨å¯¹è±¡ä¸­è·å–navigatorï¼Œå…¶ä¸­åŒ…å«æµè§ˆå™¨çš„åŸºæœ¬ä¿¡æ¯
     * 2ã€åœ¨navigatorå¯¹è±¡ä¸­è·å–gpuï¼Œå¦‚æœå½“å‰æµè§ˆå™¨ä¸æ”¯æŒï¼Œåˆ™è·å–ä¸ºç©º
     * 3ã€å¼‚æ­¥è·å–gpué€‚é…å™¨ï¼Œadapteræè¿°äº†æ˜¾å¡çš„åŸºæœ¬ä¿¡æ¯
     * 4ã€å¼‚æ­¥è·å–è®¾å¤‡ï¼Œå³ä¸ºæ˜¾å¡çš„å¼•ç”¨ã€‚ç”¨æ¥æ“çºµæ˜¾å¡ï¼Œè¿˜å¯ä»¥åˆ›å»ºæ•°æ®ç»“æ„
     * 5ã€queueæ˜¯ç”¨æ¥å‘GPUå‘é€å¼‚æ­¥ä»»åŠ¡çš„
     * @returns 
     */
    async function initialGPU(): Promise<[GPUAdapter, GPUDevice, GPUQueue] | []> {
        const navigator: any = window.navigator;
        const gpu: GPU = navigator.gpu;
        if (!gpu) {
            alert('ä½ çš„æµè§ˆå™¨ä¸æ”¯æŒ WebGPU æˆ–æœªå¼€å¯ WebGPU æ”¯æŒ')
            return []
        }
        const adapter = await gpu.requestAdapter()
        if (adapter) {
            const device = await adapter.requestDevice()
            const queue = device.queue;
            return [adapter, device, queue]
        } else {
            return []
        }
    }

    /**
     * é…ç½®ä¸Šä¸‹æ–‡
     * @param canvas 
     * @param context 
     * @param device 
     * @param presentationFormat 
     */
    function configContext(canvas: HTMLElement, context: any, device: any, presentationFormat: any) {
        const devicePixelRatio = window.devicePixelRatio || 1;
        const presentationSize = [
            canvas.clientWidth * devicePixelRatio,
            canvas.clientHeight * devicePixelRatio,
        ]

        context.configure({
            device,
            format: presentationFormat,
            size: presentationSize,
            usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.COPY_SRC,
            alphaMode: 'opaque'
        })
    }

    /**
     * webGPUæ¸²æŸ“ä¸‰è§’å½¢
     * @returns 
     */
    async function renderGPU() {
        const canvas: any = document.getElementById('webGPUCanvas')
        const [adapter, device, queue] = await initialGPU()
        if (!adapter || !device || !queue) {
            return
        }

        // ä¸ºäº†æ˜¾ç¤ºæ¸²æŸ“çš„å†…å®¹ï¼Œéœ€è¦æœ‰ä¸€ä¸ªè½½ä½“æ˜¾ç¤ºï¼ŒwebGPUé‡‡ç”¨canvasï¼Œwgpuå¯ä»¥ç”¨winitçª—å£ã€‚
        const context = canvas.getContext('webgpu')
        const presentationFormat = context.getPreferredFormat(adapter)
        configContext(canvas, context, device, presentationFormat);

        let vertModule: GPUShaderModule = device.createShaderModule({
            code: VertexShaderCode
        });

        let fragModule: GPUShaderModule = device.createShaderModule({
            code: FragmentShaderCode
        });

        const depthTextureDesc: GPUTextureDescriptor = {
            size: [canvas.width, canvas.height, 1],
            dimension: '2d',
            format: 'depth24plus-stencil8',
            usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.COPY_SRC
        };

        const pipeline = device.createRenderPipeline({
            vertex: {
                module: vertModule,
                entryPoint: 'main',
            },

            fragment: {
                module: fragModule,
                entryPoint: 'main',
                targets: [
                    {
                        format: presentationFormat
                    }
                ]
            },

            primitive: {
                topology: 'triangle-list',
            }
        })

        // ä½¿ç”¨deviceåˆ›å»ºæŒ‡ä»¤ç¼–ç å™¨
        const commandEncoder = device.createCommandEncoder()
        const textureView = context.getCurrentTexture().createView()
        const renderPassDescriptor = {
            colorAttachments: [
                {
                    view: textureView,
                    loadValue: {
                        r: 0.0,
                        g: 0.0,
                        b: 0.0,
                        a: 1.0
                    },
                    storeOp: 'store'
                }
            ]
        }

        const passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor)
        passEncoder.setPipeline(pipeline)
        passEncoder.draw(3, 1, 0, 0)
        passEncoder.endPass()

        queue.submit([commandEncoder.finish()])
    }


    async function renderTrangle() {
        const canvas: any = document.getElementById('webGPUCanvas')
        const [adapter, device, queue] = await initialGPU()
        if (!adapter || !device || !queue) {
            return
        }

        const context = canvas.getContext('webgpu')

        // ğŸ¤” Create Depth Backing
        const depthTextureDesc: GPUTextureDescriptor = {
            size: [canvas.width, canvas.height, 1],
            dimension: '2d',
            format: 'depth24plus-stencil8',
            usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.COPY_SRC
        };

        let depthTexture = device.createTexture(depthTextureDesc);
        let depthTextureView = depthTexture.createView();

        // âœ‹ Declare canvas context image handles
        let colorTexture = context.getCurrentTexture();
        let colorTextureView = colorTexture.createView();

        // ğŸ“ˆ Position Vertex Buffer Data
        const positions = new Float32Array([
            1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 1.0, 0.0
        ]);

        // ğŸ¨ Color Vertex Buffer Data
        const colors = new Float32Array([
            1.0,
            0.0,
            0.0, // ğŸ”´
            0.0,
            1.0,
            0.0, // ğŸŸ¢
            0.0,
            0.0,
            1.0 // ğŸ”µ
        ]);

        // ğŸ“‡ Index Buffer Data
        const indices = new Uint16Array([0, 1, 2]);
        // âœ‹ Declare buffer handles
        let positionBuffer = createBuffer(positions, GPUBufferUsage.VERTEX, device);
        let colorBuffer = createBuffer(colors, GPUBufferUsage.VERTEX, device);
        let indexBuffer = createBuffer(indices, GPUBufferUsage.INDEX, device);

        // âœ‹ Declare shader module handles        
        const vsmDesc = { code: TriangleVertexShaderCode };
        let vertModule = device.createShaderModule(vsmDesc);

        const fsmDesc = { code: TriangleFramentShaderCode };
        let fragModule = device.createShaderModule(fsmDesc);

        // ğŸ‘” Uniform Data
        const uniformData = new Float32Array([

            // â™Ÿï¸ ModelViewProjection Matrix (Identity)
            1.0, 0.0, 0.0, 0.0,
            0.0, 1.0, 0.0, 0.0,
            0.0, 0.0, 1.0, 0.0,
            0.0, 0.0, 0.0, 1.0,

            // ğŸ”´ Primary Color
            0.9, 0.1, 0.3, 1.0,

            // ğŸŸ£ Accent Color
            0.8, 0.2, 0.8, 1.0,
        ]);

        // âœ‹ Declare buffer handles
        let uniformBuffer = createBuffer(uniformData, GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST, device);

        // ğŸ‘¨â€ğŸ”§ Create your graphics pipeline...

        // ğŸ§™â€â™‚ï¸ Then get your implicit pipeline layout:
        let bindGroupLayout = pipeline.getBindGroupLayout(0);

        // ğŸ—„ï¸ Bind Group
        // âœ This would be used when *encoding commands*
        let uniformBindGroup = device.createBindGroup({
            layout: bindGroupLayout,
            entries: [
                {
                    binding: 0,
                    resource: {
                        buffer: uniformBuffer
                    }
                }
            ]
        });
        // âœ‹ Declare handles
        let uniformBindGroupLayout: GPUBindGroupLayout = null;
        let uniformBindGroup: GPUBindGroup = null;
        let layout: GPUPipelineLayout = null;

        // ğŸ“ Bind Group Layout
        uniformBindGroupLayout = device.createBindGroupLayout({
            entries: [
                {
                    binding: 0,
                    visibility: GPUShaderStage.VERTEX,
                    buffer: {}
                }
            ]
        });

        // ğŸ—„ï¸ Bind Group
        // âœ This would be used when *encoding commands*
        uniformBindGroup = device.createBindGroup({
            layout: uniformBindGroupLayout,
            entries: [
                {
                    binding: 0,
                    resource: {
                        buffer: uniformBuffer
                    }
                }
            ]
        });

        // ğŸ—‚ï¸ Pipeline Layout
        // ğŸ‘©â€ğŸ”§ This would be used as a member of a GPUPipelineDescriptor when *creating a pipeline*
        const pipelineLayoutDesc = { bindGroupLayouts: [uniformBindGroupLayout] };
        layout = device.createPipelineLayout(pipelineLayoutDesc);
        // âœ Later when you're encoding commands:
        passEncoder.setBindGroup(0, uniformBindGroup);
        // âœ‹ Declare pipeline handle
        let pipeline: GPURenderPipeline = null;

        // âš—ï¸ Graphics Pipeline

        // ğŸ”£ Input Assembly
        const positionAttribDesc: GPUVertexAttribute = {
            shaderLocation: 0, // @location(0)
            offset: 0,
            format: 'float32x3'
        };
        const colorAttribDesc: GPUVertexAttribute = {
            shaderLocation: 1, // @location(1)
            offset: 0,
            format: 'float32x3'
        };
        const positionBufferDesc: GPUVertexBufferLayout = {
            attributes: [positionAttribDesc],
            arrayStride: 4 * 3, // sizeof(float) * 3
            stepMode: 'vertex'
        };
        const colorBufferDesc: GPUVertexBufferLayout = {
            attributes: [colorAttribDesc],
            arrayStride: 4 * 3, // sizeof(float) * 3
            stepMode: 'vertex'
        };

        // ğŸŒ‘ Depth
        const depthStencil: GPUDepthStencilState = {
            depthWriteEnabled: true,
            depthCompare: 'less',
            format: 'depth24plus-stencil8'
        };

        // ğŸ¦„ Uniform Data
        const pipelineLayoutDesc = { bindGroupLayouts: [] };
        const layout = device.createPipelineLayout(pipelineLayoutDesc);

        // ğŸ­ Shader Stages
        const vertex: GPUVertexState = {
            module: vertModule,
            entryPoint: 'main',
            buffers: [positionBufferDesc, colorBufferDesc]
        };

        // ğŸŒ€ Color/Blend State
        const colorState: GPUColorTargetState = {
            format: 'bgra8unorm'
        };

        const fragment: GPUFragmentState = {
            module: fragModule,
            entryPoint: 'main',
            targets: [colorState]
        };

        // ğŸŸ¨ Rasterization
        const primitive: GPUPrimitiveState = {
            frontFace: 'cw',
            cullMode: 'none',
            topology: 'triangle-list'
        };

        const pipelineDesc: GPURenderPipelineDescriptor = {
            layout,
            vertex,
            fragment,
            primitive,
            depthStencil
        };

        pipeline = device.createRenderPipeline(pipelineDesc);
       

    }


    // âœï¸ Write commands to send to the GPU
    function encodeCommands() {
        let colorAttachment: GPURenderPassColorAttachment = {
            view: this.colorTextureView,
            clearValue: { r: 0, g: 0, b: 0, a: 1 },
            loadOp: 'clear',
            storeOp: 'store'
        };

        const depthAttachment: GPURenderPassDepthStencilAttachment = {
            view: this.depthTextureView,
            depthClearValue: 1,
            depthLoadOp: 'clear',
            depthStoreOp: 'store',
            stencilClearValue: 0,
            stencilLoadOp: 'clear',
            stencilStoreOp: 'store'
        };

        const renderPassDesc: GPURenderPassDescriptor = {
            colorAttachments: [colorAttachment],
            depthStencilAttachment: depthAttachment
        };

        let commandEncoder = device.createCommandEncoder();

        // ğŸ–Œï¸ Encode drawing commands
        let passEncoder = commandEncoder.beginRenderPass(renderPassDesc);
        passEncoder.setPipeline(pipeline);
        passEncoder.setViewport(0, 0, canvas.width, canvas.height, 0, 1);
        passEncoder.setScissorRect(0, 0, canvas.width, canvas.height);
        passEncoder.setVertexBuffer(0, positionBuffer);
        passEncoder.setVertexBuffer(1, colorBuffer);
        passEncoder.setIndexBuffer(indexBuffer, 'uint16');
        passEncoder.drawIndexed(3);
        passEncoder.endPass();

        queue.submit([commandEncoder.finish()]);
    };

    function render(context: any) {
        // â­ Acquire next image from context
        let colorTexture = context.getCurrentTexture();
        let colorTextureView = colorTexture.createView();

        // ğŸ“¦ Write and submit commands to queue
        encodeCommands();

        // â¿ Refresh canvas
        requestAnimationFrame(() => render(context));
    };

    // ğŸ‘‹ Helper function for creating GPUBuffer(s) out of Typed Arrays
    function createBuffer(arr: Float32Array | Uint16Array, usage: number, device: GPUDevice) {
        // ğŸ“ Align to 4 bytes (thanks @chrimsonite)
        let desc = {
            size: (arr.byteLength + 3) & ~3,
            usage,
            mappedAtCreation: true
        };
        let buffer = device.createBuffer(desc);

        const writeArray =
            arr instanceof Uint16Array
                ? new Uint16Array(buffer.getMappedRange())
                : new Float32Array(buffer.getMappedRange());
        writeArray.set(arr);
        buffer.unmap();
        return buffer;
    };

}

export default WebGPUComponent